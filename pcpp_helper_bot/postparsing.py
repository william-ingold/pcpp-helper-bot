import re

from bs4 import BeautifulSoup
from pcpp.pcppparser import PCPPParser

# Set of Regular Expressions used for searching posts
anon_list_pat = r'https://(\w+\.)?pcpartpicker\.com/list/\w+'
identifiable_list_pat = r'https://(\w+\.)?pcpartpicker\.com/user/.+'
anon_re = re.compile(anon_list_pat)
iden_re = re.compile(identifiable_list_pat)
footer_re = re.compile(r'(Total)|(Generated by)')

# So we can get anon urls from identifiable urls
pcpp_parser = PCPPParser()


class Table:
    def __init__(self, pcpp_url: str, head: BeautifulSoup, foot: BeautifulSoup):
        self.pcpp_url = pcpp_url
        self.thead = head
        self.tfoot = foot
    
    def is_valid(self):
        return self.thead is not None and self.tfoot is not None


def pcpp_table_header(tag: BeautifulSoup):
    """Find table headers that match one generated by PCPP."""
    return tag.name == 'thead' and tag.text.strip() == 'Type\nItem\nPrice'


def detect_pcpp_html_elements(text: str):
    """Detects PCPP HTML elements in the provided text.
    
    Args:
        text (str): HTML text to search.
    Returns:
        Dictionary of lists with the following keys: anon, identifiable,
        pcpp_headers,  table_headers, table_footers.
    """
    
    soup = BeautifulSoup(text, 'lxml')
    
    # Search for all the PCPP links
    anon_links = soup.find_all('a', href=anon_re)
    iden_links = soup.find_all('a', href=iden_re)
    
    # Grab the urls only
    anon_urls = [a['href'] for a in anon_links]
    iden_urls = [a['href'] for a in iden_links]
    
    table_headers = soup.find_all(pcpp_table_header)
    pcpp_tables = []
    
    # Look for appropriate table headers. Look for a
    # PCPP anon link before the table and also look for
    # a valid/expected table footer.
    for table_header in table_headers:
        list_url = table_header.find_previous('a', href=anon_re)
        if list_url:
            list_url = list_url['href']
        
        footer = table_header.find_next('td', text=footer_re)
        pcpp_tables.append(Table(list_url, table_header, footer))
    
    return {'anon': anon_urls, 'identifiable': iden_urls,
            'tables': pcpp_tables}


def get_urls_with_no_table(urls: list, tables: list):
    """Determines what urls do not have an accompanying table.
    
    Args:
        urls (list): A list of PCPP urls.
        tables (list): A list of table elements found in the post.
    
    Returns:
        List of urls that LIKELY have no accompanied table.
    """
    
    unpaired_tables = []
    
    # Remove urls that are already paired with a table.
    # Track valid tables not paired with a url.
    for table in tables:
        if table.is_valid():
            if table.pcpp_url:
                urls.remove(table.pcpp_url)
            else:
                unpaired_tables.append(table)
    
    # TODO: COULD scrape the urls and compare to tables... but seems overkill
    # If there are urls left and unpaired tables left then just assume
    # that the first X urls unpaired go with the X unpaired tables
    if len(urls) >= len(unpaired_tables):
        for i in range(len(unpaired_tables)):
            urls.pop(0)
            
    return urls


def combine_iden_anon_urls(anon_urls: list, iden_urls: list):
    """Gets the anonymous list urls for identifiable urls and combines them
    with the anonymous urls.
    
    Args:
        anon_urls (list): List of anonymous list urls.
        iden_urls (list): List of identifiable list urls.
        
    Returns:
        Previous anonymous urls along with the anonymous urls of the
        identifiable list urls (if it wasn't already in the list).
    """
    
    new_anon_urls = [PCPPParser.get_anon_list_url(url) for url in iden_urls]
    anon_urls += [url for url in new_anon_urls if url not in anon_urls]
    
    return anon_urls
